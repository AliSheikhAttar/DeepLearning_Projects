{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsYig1o-bQNO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwg8QkEcsCKD"
      },
      "source": [
        "![0.jfif](attachment:0.jfif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsmn1tJGsCKJ"
      },
      "source": [
        "# Practice 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip5W1NSMsCKK"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "    خب، حالا که هم شبکه های عصبی عادی و هم شبکه های عصبی کانولوشنی رو یاد گرفتید میخوایم بریم که چند تا شبکه ترین کنیم که ببینیم چه نتایجی رو کسب می کنیم"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyGfxHqmsCKL"
      },
      "source": [
        "# CIFAR Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo3IAFwEsCKL"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "دیتاست سایفار دو ورژن داره، سایفار 10 و سایفار 100 یه سرچ ریز بزنید ببینید تفاوتاشون چیه اصلا\n",
        "برای این که خیلیم دور نرید اینم لینکاش =)\n",
        "\n",
        "https://keras.io/api/datasets/cifar10/\n",
        "https://keras.io/api/datasets/cifar100/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY66zZUGsCKM"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    با استفاده از دستورات و دیتاست های موجود در keras \n",
        "    ابتدا دیتاست سایفار10 رو لود کنید"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfdIKrmRsCKM"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    بعدش هم کتابخونه هایی که نیازتون میشه رو ایمپورت کنید، چیا هستن؟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KbRUa4ncsCKN",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3lPgSsZsCKO"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    داده های تست و ترین رو به همراه لیبل هاشون لود کنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POSz5zj0sCKP",
        "outputId": "fe96f617-7dbe-44bb-b455-b9ce4d9dbd2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intZiyHXsCKP"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    شیپ کلی دیتاستتون رو پرینت کنید که ببینید چه تعداد عکس ترین و چه تعداد عکس تست دارید همچنین شکل لیبل هاتون رو ببینید چطوریه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrjE60jhsCKQ",
        "outputId": "da6c074f-f6d9-4587-ae1e-389cd4cdbde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSCDnzz4zH3L",
        "outputId": "2b000c66-1567-4d28-942c-2239f84adfce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3EBN8xfsCKQ"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    با استفاده از متپلات لیب ، یکی از عکس های دیتاستتون رو نمایش بدین که یه شکل کلی دستتون بیاد که دیتاستتون شامل چیا هستش"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-ehRmU5EsCKQ",
        "outputId": "84c444a6-e1a8-4308-b475-fa99391318f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label :  [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image_index = 93\n",
        "plt.imshow(x_train[image_index] )\n",
        "print('Label : ', y_train[image_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8UNowZtsCKR"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a1kweRCsCKR"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "در این مرحله میخوایم که یک ANN \n",
        "    روی تصاویر دیتاست سایفار فیت کنیم. منتهی قبلش نیاز داریم که چند تا کار انجام بدیم روی داده ها!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9jZ5OSYsCKR"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    اول از همه، روی خود تصاویر چه تغییری باید انجام بدیم؟ اولا میخوایم مقادیر پیکسل ها بین 0 تا 1 باشه بعدشم باید تصاویر طوری باشند که قابل ورودی دادن به شبکه ی ANN باشند\n",
        "    پس باید چیکار کنیم؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Ip_bc1w665"
      },
      "source": [
        "برای اینکه مقادیر ورودی بین 0 و 1 باشند می توانیم از انواع روش های اسکیل برای آن ها استفاده کنیم یا تمام مقادیر را بر 255 تقسیم کنیم و برای اینکه تصاویر قابل ورودی دادن به شبکه باشند باید به یک بردار تبدیل شوند یا به اصطلاح (flatten) شوند "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhnbBs70sCKS"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    یه نکته ی خیلی مهم: داده هاتون رنگین! یعنی چی؟ یعنی 3 تا کانال دارن! یعنی چی؟ یعنی وقتی دارید شیپ هارو تغییر میدید بیشتر دقت کنید!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ciGaUhcFsCKS",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train.reshape(-1,32*32*3)/255\n",
        "x_test_final = x_test.reshape(-1,32*32*3)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyLy6HytsCKS"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    برای این که مطمئن بشید که دیتاتون به اون صورتیه میخواید، شیپ هاشون رو پرینت بکنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRZBQVtXsCKS",
        "outputId": "ad5a4f64-0827-4756-f33c-7ec8b355b923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 3072)\n",
            "(10000, 3072)\n"
          ]
        }
      ],
      "source": [
        "print(x_train_final.shape)\n",
        "print(x_test_final.shape)\n",
        "\n",
        "#Expected Output : \n",
        "# (50000,3072)\n",
        "# (10000,3072)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-OKS9EbsCKT"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا باید فرمت لیبل ها به اون صورتی باشه که خروجی شبکه مون هست! یعنی 10 تایی\n",
        "پس با استفاده از تابع\n",
        "to_categorical\n",
        "از کراس لیبل های مطلوب رو بسازید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9aKOg-E-sCKT"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "numberof_classes = 10\n",
        "y_train_cat = to_categorical(y_train, numberof_classes)\n",
        "y_test_cat = to_categorical(y_test, numberof_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YC-tvfRzxOB",
        "outputId": "85c86ea5-76c9-4eda-bd9b-1cc173053d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_train_cat[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWsI4aPwsCKT"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا باید مدلتون رو بسازید\n",
        "اول از همه اون کلاس ها و توابع و لایه هایی که نیاز دارید رو ایمپورت کنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IXK-i4RHsCKT"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UREhRGIIsCKU"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا مدلتون رو بسازید\n",
        "\n",
        "    1. مدلتون رو به صورت Sequential بسازید\n",
        "    2. لایه ی اولیه رو لایه ی Input قرار بدید و شکل ورودی رو براش مشخص کنید\n",
        "    3. بعد لایه های Dense به به ترتیب با تعداد نود های 512و512و1024و10 قرار بدید و اکتیویشن های مناسب رو برای هر کدوم قرار بدید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y1qBcIwIsCKU"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape = (32*32*3)))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(1024, activation = 'relu'))\n",
        "model.add(Dense(10 , activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzu7ijOCsCKU"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "مدلتون رو کامپایل کنید\n",
        "تابع هزینه تون رو categorical_crossentrpy قرار بدید و از اپتیمایزر adam استفاده کنید\n",
        "    \n",
        "    همچنین از متریک accuracy استفاده کنید که نتایج شبکه تون براتون ملموس تر باشه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V_EmdpRisCKV"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',  metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgu9yaSOsCKV"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "خلاصه ی مدلتون رو نگاه کنید\n",
        "چه تعداد پارامتر دارید؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_BFfO2K4-DL"
      },
      "source": [
        "2,371,594"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q4cNbDmsCKW",
        "outputId": "29d6baac-107d-4609-ade0-cff97083b7e7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,371,594\n",
            "Trainable params: 2,371,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3UfVc-sCKW"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "مدلتون رو روی دیتاهایی که آماده کردید فیت کنید، از آرگمان های زیر استفاده کنید.\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "داده های ولیدیشن هم یادتون نره! شما میخواید نتیجه ی مدلتون روی دیتاست test خوب باشه پس اونم باید توی آموزش در نظر بگیرید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybX36slLsCKW",
        "outputId": "7f01f56e-7431-4fcc-911b-d7965ff8daac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 8s 13ms/step - loss: 1.8510 - accuracy: 0.3304 - val_loss: 1.6985 - val_accuracy: 0.3887\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.6494 - accuracy: 0.4068 - val_loss: 1.5645 - val_accuracy: 0.4408\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5645 - accuracy: 0.4366 - val_loss: 1.5482 - val_accuracy: 0.4413\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.5003 - accuracy: 0.4626 - val_loss: 1.4826 - val_accuracy: 0.4770\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4580 - accuracy: 0.4765 - val_loss: 1.5126 - val_accuracy: 0.4575\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.4086 - accuracy: 0.4935 - val_loss: 1.4326 - val_accuracy: 0.4876\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3659 - accuracy: 0.5089 - val_loss: 1.4557 - val_accuracy: 0.4859\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.3308 - accuracy: 0.5233 - val_loss: 1.4271 - val_accuracy: 0.4937\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2968 - accuracy: 0.5346 - val_loss: 1.4226 - val_accuracy: 0.4970\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.2497 - accuracy: 0.5513 - val_loss: 1.4131 - val_accuracy: 0.5043\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.2120 - accuracy: 0.5653 - val_loss: 1.4181 - val_accuracy: 0.5043\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1670 - accuracy: 0.5801 - val_loss: 1.3922 - val_accuracy: 0.5126\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.1275 - accuracy: 0.5927 - val_loss: 1.4183 - val_accuracy: 0.5065\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0750 - accuracy: 0.6108 - val_loss: 1.4404 - val_accuracy: 0.5174\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 1.0200 - accuracy: 0.6326 - val_loss: 1.4438 - val_accuracy: 0.5171\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9735 - accuracy: 0.6478 - val_loss: 1.5048 - val_accuracy: 0.5043\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.9247 - accuracy: 0.6640 - val_loss: 1.5027 - val_accuracy: 0.5164\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.8525 - accuracy: 0.6911 - val_loss: 1.5909 - val_accuracy: 0.5011\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.7995 - accuracy: 0.7113 - val_loss: 1.6113 - val_accuracy: 0.5056\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7381 - accuracy: 0.7338 - val_loss: 1.6524 - val_accuracy: 0.5041\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6901 - accuracy: 0.7526 - val_loss: 1.6977 - val_accuracy: 0.4981\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6358 - accuracy: 0.7706 - val_loss: 1.8406 - val_accuracy: 0.5015\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.5837 - accuracy: 0.7885 - val_loss: 1.8594 - val_accuracy: 0.5058\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.5299 - accuracy: 0.8085 - val_loss: 2.0224 - val_accuracy: 0.5015\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4795 - accuracy: 0.8275 - val_loss: 2.0454 - val_accuracy: 0.5013\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.4316 - accuracy: 0.8454 - val_loss: 2.1863 - val_accuracy: 0.4961\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.4092 - accuracy: 0.8528 - val_loss: 2.2527 - val_accuracy: 0.5023\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.3709 - accuracy: 0.8666 - val_loss: 2.4342 - val_accuracy: 0.4845\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3576 - accuracy: 0.8715 - val_loss: 2.5056 - val_accuracy: 0.4936\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 3s 9ms/step - loss: 0.3259 - accuracy: 0.8834 - val_loss: 2.5711 - val_accuracy: 0.4911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb302da810>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.fit(x_train_final, y_train_cat,batch_size= 128 ,epochs= 30,\n",
        "          verbose= 1,validation_data=(x_test_final,y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgnHq9TUsCKW"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "نتایج چطور بود؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozaqEy-x2JQ6"
      },
      "source": [
        "افتضاح "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xpsq1a7sCKX"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ZMtQAMsCKX"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "   حالا بیاید یه شبکه ی CNN بزنیم!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKXJJraAsCKX"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "مثل قبل اولین کاری که باید بکنید اینه که داده هاتون رو به صورت مناسب تبدیل کنید\n",
        "پس داده هاتون باید بین 0 تا 1 باشند"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-SuVS2H4sCKY"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train/255\n",
        "x_test_final = x_test/255\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DRQM09YsCKY"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا باید فرمت لیبل ها به اون صورتی باشه که خروجی شبکه مون هست! یعنی 10 تایی\n",
        "پس با استفاده از تابع\n",
        "to_categorical\n",
        "از کراس لیبل های مطلوب رو بسازید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4Xg0nZa6sCKY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "numberof_classes = 10\n",
        "y_train_cat = to_categorical(y_train, numberof_classes)\n",
        "y_test_cat = to_categorical(y_test, numberof_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbIh7jCgsCKY"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا باید مدلتون رو بسازید\n",
        "اول از همه اون کلاس ها و توابع و لایه هایی که نیاز دارید رو ایمپورت کنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F_YuOOmZsCKY"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1A6U1zOsCKY"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "حالا مدلتون رو بسازید\n",
        "    \n",
        "    1. مدل رو به صورت Sequential تعریف کنید\n",
        "\n",
        "    2. لایه ی ورودی رو به شبکه تون اضافه کنید و شیپی که قبول می کنه براش مشخص کنید\n",
        "\n",
        "    3. سه تا لایه ی کانولوشنی به ترتیب با تعداد فیلتر های 32 و 32 و 32 بسازید\n",
        "\n",
        "    4. یک لایه ی مکس پولینگ برای شبکه تون قرار بدید\n",
        "    \n",
        "    5. یک لایه ی فلتن به مدلتون اضافه کنید\n",
        "    \n",
        "6. 3 لایه ی دنس با تعداد نود های به ترتیب 64، 32، 10 بسازید و اکتیوشن های مناسب رو قرار بدید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jdaWzjR4sCKZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu', input_shape = (32,32,3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH1MilklsCKZ"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "مدلتون رو کامپایل کنید\n",
        "تابع هزینه تون رو categorical_crossentrpy قرار بدید و از اپتیمایزر adam استفاده کنید\n",
        "    \n",
        "    همچنین از متریک accuracy استفاده کنید که نتایج شبکه تون براتون ملموس تر باشه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UKtfZQlksCKZ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lJusJjbsCKZ"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "خلاصه ی مدلتون رو نگاه کنید\n",
        "چه تعداد پارامتر دارید؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNqBi4Uq3sPQ"
      },
      "source": [
        "367,978"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtsuEgCCsCKZ",
        "outputId": "bba62d09-3a3c-4ec8-8efa-bb777cf0b9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                346176    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 367,978\n",
            "Trainable params: 367,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSt4VOq2sCKZ"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "مدلتون رو روی دیتاهایی که آماده کردید فیت کنید، از آرگمان های زیر استفاده کنید.\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "داده های ولیدیشن هم یادتون نره! شما میخواید نتیجه ی مدلتون روی دیتاست test خوب باشه پس اونم باید توی آموزش در نظر بگیرید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89QX6PNvsCKa",
        "outputId": "cc952ade-ede2-4ee5-f5b9-9f62ae846ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 [==============================] - 15s 19ms/step - loss: 1.6360 - accuracy: 0.4013 - val_loss: 1.3223 - val_accuracy: 0.5243\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 1.2070 - accuracy: 0.5686 - val_loss: 1.1011 - val_accuracy: 0.6090\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 1.0196 - accuracy: 0.6440 - val_loss: 1.0080 - val_accuracy: 0.6451\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.9176 - accuracy: 0.6782 - val_loss: 1.0396 - val_accuracy: 0.6352\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.8499 - accuracy: 0.7017 - val_loss: 0.9558 - val_accuracy: 0.6674\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7884 - accuracy: 0.7250 - val_loss: 0.9807 - val_accuracy: 0.6653\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.7409 - accuracy: 0.7421 - val_loss: 0.9454 - val_accuracy: 0.6799\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6879 - accuracy: 0.7598 - val_loss: 0.9652 - val_accuracy: 0.6694\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6430 - accuracy: 0.7743 - val_loss: 0.9404 - val_accuracy: 0.6834\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.6023 - accuracy: 0.7899 - val_loss: 0.9735 - val_accuracy: 0.6779\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.5609 - accuracy: 0.8036 - val_loss: 1.0035 - val_accuracy: 0.6808\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.5197 - accuracy: 0.8159 - val_loss: 1.0658 - val_accuracy: 0.6732\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.4757 - accuracy: 0.8310 - val_loss: 1.1298 - val_accuracy: 0.6677\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4367 - accuracy: 0.8456 - val_loss: 1.1986 - val_accuracy: 0.6604\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4064 - accuracy: 0.8554 - val_loss: 1.2517 - val_accuracy: 0.6624\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3680 - accuracy: 0.8706 - val_loss: 1.3441 - val_accuracy: 0.6461\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.3351 - accuracy: 0.8803 - val_loss: 1.4194 - val_accuracy: 0.6513\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.3048 - accuracy: 0.8927 - val_loss: 1.4996 - val_accuracy: 0.6446\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2769 - accuracy: 0.9026 - val_loss: 1.6062 - val_accuracy: 0.6537\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2555 - accuracy: 0.9098 - val_loss: 1.6643 - val_accuracy: 0.6446\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2263 - accuracy: 0.9196 - val_loss: 1.7421 - val_accuracy: 0.6469\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2081 - accuracy: 0.9266 - val_loss: 1.9023 - val_accuracy: 0.6353\n",
            "Epoch 23/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1875 - accuracy: 0.9335 - val_loss: 1.9492 - val_accuracy: 0.6394\n",
            "Epoch 24/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1742 - accuracy: 0.9369 - val_loss: 2.0597 - val_accuracy: 0.6445\n",
            "Epoch 25/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1494 - accuracy: 0.9478 - val_loss: 2.2921 - val_accuracy: 0.6340\n",
            "Epoch 26/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1467 - accuracy: 0.9490 - val_loss: 2.3447 - val_accuracy: 0.6340\n",
            "Epoch 27/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1421 - accuracy: 0.9490 - val_loss: 2.4535 - val_accuracy: 0.6365\n",
            "Epoch 28/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1335 - accuracy: 0.9527 - val_loss: 2.4373 - val_accuracy: 0.6366\n",
            "Epoch 29/30\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1158 - accuracy: 0.9588 - val_loss: 2.6235 - val_accuracy: 0.6332\n",
            "Epoch 30/30\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1249 - accuracy: 0.9563 - val_loss: 2.5117 - val_accuracy: 0.6356\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbac12d0bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.fit(x_train_final, y_train_cat,batch_size= 128 ,epochs= 30, \n",
        "          verbose= 1, validation_data=(x_test_final,y_test_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BuCBvxFksCKa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJoWyn6sCKa"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwmHAQydsCKa"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    خب خسته نباشید!\n",
        "    حالا نتایج رو با هم مقایسه کنید."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAIfsrn8sCKa"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "تعداد پارامترهای مدل ANN چند برابر مدل CNN بود؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLKxMaHH5A_Y"
      },
      "source": [
        "2,371,594/367,978 = 6.44"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrBXS2CosCKa"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw2XXxaLsCKa"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "این تفاوت در دقت ناشی از چیه؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa_g_zw35P3w"
      },
      "source": [
        "چون شبکه ی ای ان ان (فارسی می نویسم چون انگلیسی جملات را به هم می زند) تمام اطلاعات تصاویر را به صورت خطی دریافت می کند متوجه رابطه ی بین پیکسل ها نمی شود و فقط به مختصات هر پیکسل نسبت به مختصات کل عکس بها می دهد و وزن ها نیز بر اساس همین تعیین می شوند ولی در شبکه ی سی ان ان وزن ها بر اساس  روابطی که پیسکل ها به صورت نسبی نسبت به یکدیگر میسازند مقداردهی می شوند "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_6mFcSesCKa"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbqdibAsCKb"
      },
      "source": [
        "# امتیازی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ1JSMhBsCKb"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    هم مدلANN و هم مدل CNN تون رو تغییر بدین!\n",
        "    \n",
        "    ببینید بالاترین دقتی که ازش میگیرید چقدر هستش\n",
        "    \n",
        "    این قسمت به صورت امتیازی هستش و اجباری نیست ولی به یادگیری خودتون خیلی کمک می کنه که بیاید نتایج رو با هم مقایسه کنید و روی مدل های مختلف آموزش انجام بدید"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Y7Ohds-isJ"
      },
      "source": [
        "# ANN - new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BmIyY8tDGNB3"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train.reshape(-1,32*32*3)/255\n",
        "x_test_final = x_test.reshape(-1,32*32*3)/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pKtNRYd8-keo"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape = (32*32*3)))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1024, activation = 'tanh'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(numberof_classes , activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zKUK223OARAx"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',  metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdyoH_xNAVxV",
        "outputId": "c259158c-5153-4b3b-e1fb-662c04f9b18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.9024 - accuracy: 0.3028 - val_loss: 1.8021 - val_accuracy: 0.3463\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.7583 - accuracy: 0.3612 - val_loss: 1.6976 - val_accuracy: 0.3874\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.6728 - accuracy: 0.3938 - val_loss: 1.6118 - val_accuracy: 0.4202\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.6219 - accuracy: 0.4146 - val_loss: 1.6344 - val_accuracy: 0.4128\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5936 - accuracy: 0.4238 - val_loss: 1.5615 - val_accuracy: 0.4426\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5642 - accuracy: 0.4351 - val_loss: 1.5976 - val_accuracy: 0.4212\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5482 - accuracy: 0.4413 - val_loss: 1.5502 - val_accuracy: 0.4440\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5265 - accuracy: 0.4495 - val_loss: 1.5338 - val_accuracy: 0.4561\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5208 - accuracy: 0.4488 - val_loss: 1.5387 - val_accuracy: 0.4518\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5074 - accuracy: 0.4534 - val_loss: 1.5514 - val_accuracy: 0.4464\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4913 - accuracy: 0.4596 - val_loss: 1.5381 - val_accuracy: 0.4479\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4780 - accuracy: 0.4634 - val_loss: 1.5301 - val_accuracy: 0.4546\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4654 - accuracy: 0.4701 - val_loss: 1.5232 - val_accuracy: 0.4550\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4552 - accuracy: 0.4732 - val_loss: 1.5474 - val_accuracy: 0.4423\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4408 - accuracy: 0.4772 - val_loss: 1.5701 - val_accuracy: 0.4365\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4267 - accuracy: 0.4837 - val_loss: 1.5612 - val_accuracy: 0.4406\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4185 - accuracy: 0.4871 - val_loss: 1.5267 - val_accuracy: 0.4608\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4002 - accuracy: 0.4901 - val_loss: 1.5902 - val_accuracy: 0.4421\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3987 - accuracy: 0.4927 - val_loss: 1.5848 - val_accuracy: 0.4354\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3920 - accuracy: 0.4951 - val_loss: 1.5622 - val_accuracy: 0.4533\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3735 - accuracy: 0.5009 - val_loss: 1.5425 - val_accuracy: 0.4583\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3677 - accuracy: 0.5009 - val_loss: 1.5984 - val_accuracy: 0.4341\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3573 - accuracy: 0.5038 - val_loss: 1.5515 - val_accuracy: 0.4534\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3501 - accuracy: 0.5079 - val_loss: 1.5581 - val_accuracy: 0.4525\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3277 - accuracy: 0.5157 - val_loss: 1.5933 - val_accuracy: 0.4529\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3181 - accuracy: 0.5156 - val_loss: 1.5983 - val_accuracy: 0.4522\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2970 - accuracy: 0.5222 - val_loss: 1.5920 - val_accuracy: 0.4514\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2931 - accuracy: 0.5249 - val_loss: 1.6044 - val_accuracy: 0.4512\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2876 - accuracy: 0.5272 - val_loss: 1.6166 - val_accuracy: 0.4413\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2671 - accuracy: 0.5361 - val_loss: 1.6023 - val_accuracy: 0.4497\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2557 - accuracy: 0.5373 - val_loss: 1.6098 - val_accuracy: 0.4454\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2367 - accuracy: 0.5451 - val_loss: 1.6321 - val_accuracy: 0.4417\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2215 - accuracy: 0.5507 - val_loss: 1.6608 - val_accuracy: 0.4507\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2213 - accuracy: 0.5480 - val_loss: 1.7181 - val_accuracy: 0.4421\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2086 - accuracy: 0.5555 - val_loss: 1.7142 - val_accuracy: 0.4355\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1826 - accuracy: 0.5647 - val_loss: 1.7673 - val_accuracy: 0.4373\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1732 - accuracy: 0.5633 - val_loss: 1.7858 - val_accuracy: 0.4306\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1617 - accuracy: 0.5708 - val_loss: 1.7325 - val_accuracy: 0.4370\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1550 - accuracy: 0.5721 - val_loss: 1.7582 - val_accuracy: 0.4406\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1323 - accuracy: 0.5791 - val_loss: 1.7929 - val_accuracy: 0.4293\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1249 - accuracy: 0.5830 - val_loss: 1.8231 - val_accuracy: 0.4419\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 1.1007 - accuracy: 0.5910 - val_loss: 1.8655 - val_accuracy: 0.4272\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0839 - accuracy: 0.5961 - val_loss: 1.8199 - val_accuracy: 0.4297\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0739 - accuracy: 0.6018 - val_loss: 1.8725 - val_accuracy: 0.4319\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0570 - accuracy: 0.6072 - val_loss: 1.9405 - val_accuracy: 0.4261\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0573 - accuracy: 0.6059 - val_loss: 1.9794 - val_accuracy: 0.4176\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0237 - accuracy: 0.6208 - val_loss: 1.9159 - val_accuracy: 0.4202\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0164 - accuracy: 0.6211 - val_loss: 2.0008 - val_accuracy: 0.4306\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0282 - accuracy: 0.6171 - val_loss: 2.0140 - val_accuracy: 0.4278\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9894 - accuracy: 0.6303 - val_loss: 2.0218 - val_accuracy: 0.4322\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9755 - accuracy: 0.6364 - val_loss: 2.1243 - val_accuracy: 0.4228\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9722 - accuracy: 0.6378 - val_loss: 2.1047 - val_accuracy: 0.4224\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9569 - accuracy: 0.6432 - val_loss: 2.1388 - val_accuracy: 0.4285\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9541 - accuracy: 0.6444 - val_loss: 2.2020 - val_accuracy: 0.4185\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9192 - accuracy: 0.6578 - val_loss: 2.1975 - val_accuracy: 0.4195\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9266 - accuracy: 0.6520 - val_loss: 2.2490 - val_accuracy: 0.4108\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9110 - accuracy: 0.6586 - val_loss: 2.2652 - val_accuracy: 0.4228\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8924 - accuracy: 0.6665 - val_loss: 2.3389 - val_accuracy: 0.4162\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8724 - accuracy: 0.6738 - val_loss: 2.2838 - val_accuracy: 0.4170\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8462 - accuracy: 0.6848 - val_loss: 2.3583 - val_accuracy: 0.4216\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbac10c0790>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.fit(x_train_final, y_train_cat,batch_size= 128 ,epochs= 60,\n",
        "          verbose= 1,validation_data=(x_test_final,y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBugfApS-ky3"
      },
      "source": [
        "# CNN - new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "G9foVe0PAmIx"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train/255\n",
        "x_test_final = x_test/255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KCx4uvDuApSc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "numberof_classes = 10\n",
        "y_train_cat = to_categorical(y_train, numberof_classes)\n",
        "y_test_cat = to_categorical(y_test, numberof_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HAu5pvx7AsNk"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9CvwdWkvAwgA"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu', input_shape = (32,32,3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1024, activation = 'tanh'))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hrz2dqxgA0Yt"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',  metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_e_yQQf-pjZ",
        "outputId": "079415e5-b3e4-49f2-e668-a76c755fad46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "391/391 [==============================] - 9s 20ms/step - loss: 1.5129 - accuracy: 0.4408 - val_loss: 1.2091 - val_accuracy: 0.5668\n",
            "Epoch 2/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 1.1142 - accuracy: 0.6021 - val_loss: 1.0649 - val_accuracy: 0.6281\n",
            "Epoch 3/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.9576 - accuracy: 0.6589 - val_loss: 1.0175 - val_accuracy: 0.6441\n",
            "Epoch 4/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.8615 - accuracy: 0.6956 - val_loss: 1.0099 - val_accuracy: 0.6455\n",
            "Epoch 5/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.7862 - accuracy: 0.7220 - val_loss: 1.0571 - val_accuracy: 0.6324\n",
            "Epoch 6/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.7174 - accuracy: 0.7477 - val_loss: 0.9906 - val_accuracy: 0.6631\n",
            "Epoch 7/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6499 - accuracy: 0.7725 - val_loss: 1.0508 - val_accuracy: 0.6525\n",
            "Epoch 8/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.6049 - accuracy: 0.7854 - val_loss: 1.0647 - val_accuracy: 0.6496\n",
            "Epoch 9/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5446 - accuracy: 0.8071 - val_loss: 1.0922 - val_accuracy: 0.6603\n",
            "Epoch 10/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.4917 - accuracy: 0.8248 - val_loss: 1.1670 - val_accuracy: 0.6539\n",
            "Epoch 11/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.4378 - accuracy: 0.8442 - val_loss: 1.2853 - val_accuracy: 0.6620\n",
            "Epoch 12/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4146 - accuracy: 0.8504 - val_loss: 1.3200 - val_accuracy: 0.6452\n",
            "Epoch 13/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.3667 - accuracy: 0.8682 - val_loss: 1.4327 - val_accuracy: 0.6327\n",
            "Epoch 14/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.3418 - accuracy: 0.8778 - val_loss: 1.5277 - val_accuracy: 0.6285\n",
            "Epoch 15/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.3217 - accuracy: 0.8840 - val_loss: 1.5181 - val_accuracy: 0.6467\n",
            "Epoch 16/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.2881 - accuracy: 0.8961 - val_loss: 1.7622 - val_accuracy: 0.6247\n",
            "Epoch 17/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.2688 - accuracy: 0.9039 - val_loss: 1.7052 - val_accuracy: 0.6412\n",
            "Epoch 18/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.2565 - accuracy: 0.9066 - val_loss: 1.8452 - val_accuracy: 0.6428\n",
            "Epoch 19/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.2326 - accuracy: 0.9160 - val_loss: 2.0021 - val_accuracy: 0.6372\n",
            "Epoch 20/60\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.2194 - accuracy: 0.9208 - val_loss: 2.1312 - val_accuracy: 0.6344\n",
            "Epoch 21/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.2020 - accuracy: 0.9262 - val_loss: 2.1401 - val_accuracy: 0.6307\n",
            "Epoch 22/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1938 - accuracy: 0.9308 - val_loss: 2.3636 - val_accuracy: 0.6305\n",
            "Epoch 23/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1936 - accuracy: 0.9300 - val_loss: 2.3809 - val_accuracy: 0.6331\n",
            "Epoch 24/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1747 - accuracy: 0.9369 - val_loss: 2.4738 - val_accuracy: 0.6260\n",
            "Epoch 25/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1718 - accuracy: 0.9389 - val_loss: 2.4586 - val_accuracy: 0.6205\n",
            "Epoch 26/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1582 - accuracy: 0.9438 - val_loss: 2.4928 - val_accuracy: 0.6311\n",
            "Epoch 27/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1673 - accuracy: 0.9410 - val_loss: 2.5963 - val_accuracy: 0.6194\n",
            "Epoch 28/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 2.6438 - val_accuracy: 0.6273\n",
            "Epoch 29/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1412 - accuracy: 0.9508 - val_loss: 2.6938 - val_accuracy: 0.6161\n",
            "Epoch 30/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1356 - accuracy: 0.9525 - val_loss: 2.8399 - val_accuracy: 0.6341\n",
            "Epoch 31/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1375 - accuracy: 0.9509 - val_loss: 2.7863 - val_accuracy: 0.6160\n",
            "Epoch 32/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1296 - accuracy: 0.9552 - val_loss: 2.9644 - val_accuracy: 0.6126\n",
            "Epoch 33/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1299 - accuracy: 0.9549 - val_loss: 2.8774 - val_accuracy: 0.6347\n",
            "Epoch 34/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1197 - accuracy: 0.9578 - val_loss: 2.8585 - val_accuracy: 0.6252\n",
            "Epoch 35/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1286 - accuracy: 0.9537 - val_loss: 2.8043 - val_accuracy: 0.6214\n",
            "Epoch 36/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1119 - accuracy: 0.9613 - val_loss: 3.0198 - val_accuracy: 0.6109\n",
            "Epoch 37/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1338 - accuracy: 0.9527 - val_loss: 2.8839 - val_accuracy: 0.6250\n",
            "Epoch 38/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1048 - accuracy: 0.9630 - val_loss: 3.1038 - val_accuracy: 0.6260\n",
            "Epoch 39/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1092 - accuracy: 0.9626 - val_loss: 3.1521 - val_accuracy: 0.6209\n",
            "Epoch 40/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1099 - accuracy: 0.9614 - val_loss: 3.3328 - val_accuracy: 0.6283\n",
            "Epoch 41/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1020 - accuracy: 0.9645 - val_loss: 3.1575 - val_accuracy: 0.6229\n",
            "Epoch 42/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0937 - accuracy: 0.9676 - val_loss: 3.4776 - val_accuracy: 0.6175\n",
            "Epoch 43/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.1055 - accuracy: 0.9635 - val_loss: 3.2726 - val_accuracy: 0.6255\n",
            "Epoch 44/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0992 - accuracy: 0.9662 - val_loss: 3.3911 - val_accuracy: 0.6175\n",
            "Epoch 45/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1159 - accuracy: 0.9608 - val_loss: 3.2324 - val_accuracy: 0.6243\n",
            "Epoch 46/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0894 - accuracy: 0.9685 - val_loss: 3.3111 - val_accuracy: 0.6262\n",
            "Epoch 47/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0961 - accuracy: 0.9662 - val_loss: 3.4585 - val_accuracy: 0.6206\n",
            "Epoch 48/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0965 - accuracy: 0.9663 - val_loss: 3.3028 - val_accuracy: 0.6190\n",
            "Epoch 49/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0929 - accuracy: 0.9680 - val_loss: 3.5620 - val_accuracy: 0.6228\n",
            "Epoch 50/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0940 - accuracy: 0.9678 - val_loss: 3.6816 - val_accuracy: 0.6183\n",
            "Epoch 51/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0904 - accuracy: 0.9691 - val_loss: 3.6836 - val_accuracy: 0.6246\n",
            "Epoch 52/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0757 - accuracy: 0.9740 - val_loss: 3.6985 - val_accuracy: 0.6259\n",
            "Epoch 53/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0938 - accuracy: 0.9693 - val_loss: 3.4652 - val_accuracy: 0.6250\n",
            "Epoch 54/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0818 - accuracy: 0.9721 - val_loss: 3.5702 - val_accuracy: 0.6288\n",
            "Epoch 55/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0994 - accuracy: 0.9677 - val_loss: 2.9410 - val_accuracy: 0.6162\n",
            "Epoch 56/60\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.0800 - accuracy: 0.9728 - val_loss: 3.4467 - val_accuracy: 0.6253\n",
            "Epoch 57/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0814 - accuracy: 0.9728 - val_loss: 3.6614 - val_accuracy: 0.6200\n",
            "Epoch 58/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0871 - accuracy: 0.9698 - val_loss: 3.7650 - val_accuracy: 0.6245\n",
            "Epoch 59/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 3.8068 - val_accuracy: 0.6206\n",
            "Epoch 60/60\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.0794 - accuracy: 0.9732 - val_loss: 3.7693 - val_accuracy: 0.6162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbac0eba050>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.fit(x_train_final, y_train_cat,batch_size= 128 ,epochs= 60, \n",
        "          verbose= 1, validation_data=(x_test_final,y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhadU3fwsCKb"
      },
      "source": [
        "<div dir=\"auto\">\n",
        "    موفق باشید"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Ali_Sheikh_Attar_Practice_4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}